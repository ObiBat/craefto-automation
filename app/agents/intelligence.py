"""
Business Intelligence Agent for CRAEFTO Automation System
Provides data-driven insights, performance analysis, and strategic optimization
"""
import asyncio
import logging
import json
import statistics
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
from collections import defaultdict, Counter
import math
import re

from app.config import get_settings
from app.utils.database import get_database

# Configure logging
logger = logging.getLogger(__name__)

class BusinessIntelligence:
    """
    AI-powered business intelligence for content strategy optimization
    Analyzes performance data and provides actionable insights
    """
    
    def __init__(self):
        self.settings = get_settings()
        self.metrics_window = 7  # days for analysis window
        self.db = get_database()
        
        # Performance thresholds for classification
        self.performance_thresholds = {
            "high_engagement": 0.05,  # 5% engagement rate
            "viral_threshold": 1000,  # views for viral content
            "conversion_rate": 0.02   # 2% conversion rate
        }
        
        # Content scoring weights
        self.scoring_weights = {
            "engagement_rate": 0.3,
            "reach": 0.25,
            "conversion": 0.2,
            "shareability": 0.15,
            "trend_alignment": 0.1
        }
        
        # Viral content indicators
        self.viral_indicators = {
            "emotional_triggers": [
                "shocking", "amazing", "incredible", "unbelievable", "secret",
                "hack", "trick", "mistake", "failure", "success", "breakthrough"
            ],
            "urgency_words": [
                "now", "today", "urgent", "limited", "exclusive", "breaking",
                "just", "finally", "immediately", "last chance"
            ],
            "social_proof": [
                "everyone", "thousands", "millions", "experts", "proven",
                "tested", "validated", "recommended", "trending"
            ]
        }
        
        # SaaS-specific content categories
        self.content_categories = {
            "tutorials": ["how to", "guide", "tutorial", "step by step", "walkthrough"],
            "insights": ["trends", "data", "analysis", "report", "insights", "statistics"],
            "tools": ["tool", "software", "platform", "app", "solution"],
            "growth": ["growth", "scaling", "optimization", "conversion", "revenue"],
            "design": ["design", "ui", "ux", "template", "layout", "visual"]
        }
    
    async def analyze_performance(self) -> Dict[str, Any]:
        """
        Comprehensive performance analysis across all content and platforms
        
        Returns:
            Detailed performance insights with actionable recommendations
        """
        logger.info("üîç Starting comprehensive performance analysis...")
        
        try:
            # Get performance data from database
            end_date = datetime.utcnow()
            start_date = end_date - timedelta(days=self.metrics_window)
            
            if not self.db.is_connected:
                return self._generate_mock_analysis()
            
            # Gather all performance data
            performance_data = await self._gather_performance_data(start_date, end_date)
            
            # Analyze different aspects
            topic_analysis = await self._analyze_topic_performance(performance_data)
            timing_analysis = await self._analyze_optimal_timing(performance_data)
            format_analysis = await self._analyze_format_performance(performance_data)
            platform_analysis = await self._analyze_platform_performance(performance_data)
            conversion_analysis = await self._analyze_conversion_rates(performance_data)
            
            # Generate insights and recommendations
            insights = await self._generate_insights(
                topic_analysis, timing_analysis, format_analysis, 
                platform_analysis, conversion_analysis
            )
            
            # Calculate overall health score
            health_score = self._calculate_content_health_score(performance_data)
            
            analysis_result = {
                "analysis_period": {
                    "start_date": start_date.isoformat(),
                    "end_date": end_date.isoformat(),
                    "days": self.metrics_window
                },
                "content_health_score": health_score,
                "topic_performance": topic_analysis,
                "optimal_timing": timing_analysis,
                "format_performance": format_analysis,
                "platform_performance": platform_analysis,
                "conversion_analysis": conversion_analysis,
                "key_insights": insights,
                "recommendations": await self._generate_recommendations(insights),
                "analyzed_at": datetime.utcnow().isoformat()
            }
            
            logger.info(f"‚úÖ Performance analysis completed. Health score: {health_score}/100")
            return analysis_result
            
        except Exception as e:
            logger.error(f"‚ùå Performance analysis failed: {str(e)}")
            return {"error": str(e), "fallback_data": self._generate_mock_analysis()}
    
    async def optimize_content_strategy(self) -> Dict[str, Any]:
        """
        AI-powered content strategy optimization based on performance data
        
        Returns:
            Optimized content strategy with specific adjustments
        """
        logger.info("üéØ Optimizing content strategy based on performance data...")
        
        try:
            # Get current performance analysis
            performance_analysis = await self.analyze_performance()
            
            if "error" in performance_analysis:
                return self._generate_mock_strategy_optimization()
            
            # Extract optimization opportunities
            focus_topics = self._identify_winning_topics(performance_analysis["topic_performance"])
            optimal_schedule = self._optimize_publishing_schedule(performance_analysis["optimal_timing"])
            content_mix = self._optimize_content_mix(performance_analysis["format_performance"])
            prompt_improvements = self._suggest_prompt_improvements(performance_analysis)
            
            # Calculate expected impact
            expected_improvements = self._calculate_expected_improvements(
                focus_topics, optimal_schedule, content_mix
            )
            
            optimization_result = {
                "strategy_optimization": {
                    "focus_topics": focus_topics,
                    "optimal_schedule": optimal_schedule,
                    "content_mix": content_mix,
                    "prompt_improvements": prompt_improvements
                },
                "expected_improvements": expected_improvements,
                "implementation_priority": self._prioritize_optimizations(
                    focus_topics, optimal_schedule, content_mix, prompt_improvements
                ),
                "next_actions": self._generate_next_actions(focus_topics, optimal_schedule, content_mix),
                "optimized_at": datetime.utcnow().isoformat()
            }
            
            logger.info("‚úÖ Content strategy optimization completed")
            return optimization_result
            
        except Exception as e:
            logger.error(f"‚ùå Strategy optimization failed: {str(e)}")
            return {"error": str(e), "fallback_data": self._generate_mock_strategy_optimization()}
    
    async def competitor_tracking(self) -> Dict[str, Any]:
        """
        Monitor and analyze competitor content strategy
        
        Returns:
            Competitor insights and opportunities
        """
        logger.info("üëÅÔ∏è Analyzing competitor content landscape...")
        
        try:
            # Define key competitors in the SaaS/Framer space
            competitors = [
                {"name": "Framer", "url": "https://framer.com/blog", "focus": "design_tools"},
                {"name": "Webflow", "url": "https://webflow.com/blog", "focus": "web_design"},
                {"name": "Figma", "url": "https://figma.com/blog", "focus": "design_collaboration"},
                {"name": "Notion", "url": "https://notion.so/blog", "focus": "productivity"},
                {"name": "Linear", "url": "https://linear.app/blog", "focus": "project_management"}
            ]
            
            competitor_analysis = {}
            content_gaps = []
            trending_topics = []
            
            for competitor in competitors:
                analysis = await self._analyze_competitor(competitor)
                competitor_analysis[competitor["name"]] = analysis
                
                # Identify content gaps
                gaps = self._identify_content_gaps(analysis, competitor["focus"])
                content_gaps.extend(gaps)
                
                # Extract trending topics
                trends = self._extract_trending_topics(analysis)
                trending_topics.extend(trends)
            
            # Consolidate findings
            consolidated_gaps = self._consolidate_content_gaps(content_gaps)
            trending_summary = self._summarize_trending_topics(trending_topics)
            competitive_opportunities = self._identify_competitive_opportunities(competitor_analysis)
            
            tracking_result = {
                "competitor_analysis": competitor_analysis,
                "content_gaps": consolidated_gaps,
                "trending_topics": trending_summary,
                "competitive_opportunities": competitive_opportunities,
                "market_insights": self._generate_market_insights(competitor_analysis),
                "recommended_responses": self._suggest_competitive_responses(competitive_opportunities),
                "tracked_at": datetime.utcnow().isoformat()
            }
            
            logger.info(f"‚úÖ Competitor tracking completed. Found {len(consolidated_gaps)} content gaps")
            return tracking_result
            
        except Exception as e:
            logger.error(f"‚ùå Competitor tracking failed: {str(e)}")
            return {"error": str(e), "fallback_data": self._generate_mock_competitor_tracking()}
    
    async def generate_report(self, report_type: str = "daily") -> Dict[str, Any]:
        """
        Generate automated performance reports
        
        Args:
            report_type: Type of report (daily, weekly, monthly)
            
        Returns:
            Formatted report with insights and recommendations
        """
        logger.info(f"üìä Generating {report_type} performance report...")
        
        try:
            # Adjust analysis window based on report type
            if report_type == "daily":
                analysis_days = 1
                comparison_days = 7  # Compare to last week
            elif report_type == "weekly":
                analysis_days = 7
                comparison_days = 14  # Compare to previous week
            else:  # monthly
                analysis_days = 30
                comparison_days = 60  # Compare to previous month
            
            # Get performance data
            current_performance = await self._get_period_performance(analysis_days)
            comparison_performance = await self._get_period_performance(comparison_days, offset=analysis_days)
            
            # Calculate trends and changes
            performance_trends = self._calculate_performance_trends(current_performance, comparison_performance)
            
            # Get top performers
            top_content = await self._get_top_performing_content(analysis_days)
            
            # Generate summary
            executive_summary = self._generate_executive_summary(
                current_performance, performance_trends, top_content, report_type
            )
            
            # Create detailed sections
            content_summary = self._create_content_summary(current_performance, analysis_days)
            engagement_analysis = self._create_engagement_analysis(current_performance, performance_trends)
            platform_breakdown = self._create_platform_breakdown(current_performance)
            recommendations = await self._create_report_recommendations(current_performance, performance_trends)
            
            # Format for different outputs
            report_data = {
                "report_metadata": {
                    "type": report_type,
                    "period": f"Last {analysis_days} days",
                    "generated_at": datetime.utcnow().isoformat(),
                    "analysis_window": analysis_days
                },
                "executive_summary": executive_summary,
                "content_summary": content_summary,
                "engagement_analysis": engagement_analysis,
                "platform_breakdown": platform_breakdown,
                "top_performers": top_content,
                "performance_trends": performance_trends,
                "recommendations": recommendations,
                "next_steps": self._generate_next_steps(recommendations)
            }
            
            # Generate formatted outputs
            html_report = self._format_html_report(report_data)
            slack_message = self._format_slack_message(report_data)
            
            report_result = {
                "report_data": report_data,
                "formatted_outputs": {
                    "html_email": html_report,
                    "slack_message": slack_message,
                    "json_data": report_data
                }
            }
            
            logger.info(f"‚úÖ {report_type.title()} report generated successfully")
            return report_result
            
        except Exception as e:
            logger.error(f"‚ùå Report generation failed: {str(e)}")
            return {"error": str(e), "fallback_data": self._generate_mock_report(report_type)}
    
    def predict_virality(self, content: Dict[str, Any]) -> Dict[str, Any]:
        """
        AI-powered virality prediction for content
        
        Args:
            content: Content data with title, body, metadata
            
        Returns:
            Virality score (0-100) with detailed explanation
        """
        logger.info("üöÄ Predicting content virality potential...")
        
        try:
            title = content.get("title", "")
            body = content.get("body", "")
            metadata = content.get("metadata", {})
            content_type = content.get("content_type", "blog")
            
            # Initialize scoring components
            scores = {
                "emotional_trigger": 0,
                "urgency_factor": 0,
                "social_proof": 0,
                "trend_alignment": 0,
                "shareability": 0,
                "saas_relevance": 0,
                "format_bonus": 0
            }
            
            explanations = []
            
            # Analyze emotional triggers
            emotional_score, emotional_explanation = self._analyze_emotional_triggers(title, body)
            scores["emotional_trigger"] = emotional_score
            explanations.extend(emotional_explanation)
            
            # Analyze urgency factors
            urgency_score, urgency_explanation = self._analyze_urgency_factors(title, body)
            scores["urgency_factor"] = urgency_score
            explanations.extend(urgency_explanation)
            
            # Analyze social proof elements
            social_score, social_explanation = self._analyze_social_proof(title, body)
            scores["social_proof"] = social_score
            explanations.extend(social_explanation)
            
            # Analyze trend alignment
            trend_score, trend_explanation = self._analyze_trend_alignment(title, body, metadata)
            scores["trend_alignment"] = trend_score
            explanations.extend(trend_explanation)
            
            # Analyze shareability factors
            share_score, share_explanation = self._analyze_shareability(title, body, content_type)
            scores["shareability"] = share_score
            explanations.extend(share_explanation)
            
            # Analyze SaaS relevance
            saas_score, saas_explanation = self._analyze_saas_relevance(title, body)
            scores["saas_relevance"] = saas_score
            explanations.extend(saas_explanation)
            
            # Format-specific bonus
            format_score, format_explanation = self._analyze_format_bonus(content_type, metadata)
            scores["format_bonus"] = format_score
            explanations.extend(format_explanation)
            
            # Calculate weighted final score
            weights = {
                "emotional_trigger": 0.25,
                "urgency_factor": 0.15,
                "social_proof": 0.15,
                "trend_alignment": 0.15,
                "shareability": 0.15,
                "saas_relevance": 0.10,
                "format_bonus": 0.05
            }
            
            final_score = sum(scores[component] * weights[component] for component in scores)
            final_score = min(100, max(0, final_score))  # Clamp to 0-100
            
            # Determine virality category
            if final_score >= 80:
                virality_category = "High Viral Potential"
                category_color = "#22c55e"  # Green
            elif final_score >= 60:
                virality_category = "Moderate Viral Potential"
                category_color = "#f59e0b"  # Yellow
            elif final_score >= 40:
                virality_category = "Low Viral Potential"
                category_color = "#ef4444"  # Red
            else:
                virality_category = "Minimal Viral Potential"
                category_color = "#6b7280"  # Gray
            
            # Generate improvement suggestions
            improvements = self._suggest_virality_improvements(scores, content)
            
            prediction_result = {
                "virality_score": round(final_score, 1),
                "virality_category": virality_category,
                "category_color": category_color,
                "component_scores": {k: round(v, 1) for k, v in scores.items()},
                "explanations": explanations,
                "improvements": improvements,
                "predicted_reach": self._estimate_reach(final_score, content_type),
                "success_probability": self._calculate_success_probability(final_score),
                "analyzed_at": datetime.utcnow().isoformat()
            }
            
            logger.info(f"‚úÖ Virality prediction completed. Score: {final_score}/100")
            return prediction_result
            
        except Exception as e:
            logger.error(f"‚ùå Virality prediction failed: {str(e)}")
            return {"error": str(e), "fallback_score": 50}
    
    # Private helper methods for data analysis
    
    async def _gather_performance_data(self, start_date: datetime, end_date: datetime) -> Dict[str, Any]:
        """Gather comprehensive performance data from database"""
        try:
            # Get analytics data
            analytics = await self.db.get_analytics_data(days=self.metrics_window)
            
            # Get top performing content
            top_content = await self.db.get_top_performing(metric="engagement_rate", limit=20, days=self.metrics_window)
            
            # Get recent content for analysis
            recent_content = await self.db.get_recent_content(limit=50)
            
            return {
                "analytics": analytics,
                "top_content": top_content,
                "recent_content": recent_content,
                "period": {"start": start_date, "end": end_date}
            }
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to gather performance data: {str(e)}")
            return self._generate_mock_performance_data()
    
    async def _analyze_topic_performance(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze performance by topic and content category"""
        topic_metrics = defaultdict(lambda: {
            "total_views": 0,
            "total_engagement": 0,
            "content_count": 0,
            "avg_engagement_rate": 0,
            "top_performing": []
        })
        
        # Process content data
        for content in data.get("recent_content", []):
            topics = self._extract_topics_from_content(content)
            
            for topic in topics:
                metrics = topic_metrics[topic]
                metrics["content_count"] += 1
                
                # Add performance data if available
                if "performance_metrics" in content:
                    perf = content["performance_metrics"]
                    metrics["total_views"] += perf.get("views", 0)
                    metrics["total_engagement"] += perf.get("engagement", 0)
        
        # Calculate averages and identify top performers
        for topic, metrics in topic_metrics.items():
            if metrics["content_count"] > 0:
                metrics["avg_engagement_rate"] = metrics["total_engagement"] / max(metrics["total_views"], 1)
                metrics["avg_views"] = metrics["total_views"] / metrics["content_count"]
        
        # Sort by performance
        sorted_topics = sorted(
            topic_metrics.items(),
            key=lambda x: x[1]["avg_engagement_rate"],
            reverse=True
        )
        
        return {
            "topic_rankings": dict(sorted_topics[:10]),
            "emerging_topics": self._identify_emerging_topics(topic_metrics),
            "declining_topics": self._identify_declining_topics(topic_metrics),
            "topic_recommendations": self._recommend_topics(sorted_topics)
        }
    
    async def _analyze_optimal_timing(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze optimal publishing times and patterns"""
        time_performance = defaultdict(lambda: {"total_engagement": 0, "content_count": 0})
        
        # Analyze by hour of day and day of week
        for content in data.get("recent_content", []):
            if "created_at" in content:
                created_at = datetime.fromisoformat(content["created_at"].replace('Z', '+00:00'))
                hour = created_at.hour
                day_of_week = created_at.strftime("%A")
                
                engagement = content.get("performance_metrics", {}).get("engagement", 0)
                
                time_performance[f"hour_{hour}"]["total_engagement"] += engagement
                time_performance[f"hour_{hour}"]["content_count"] += 1
                
                time_performance[f"day_{day_of_week}"]["total_engagement"] += engagement
                time_performance[f"day_{day_of_week}"]["content_count"] += 1
        
        # Calculate optimal times
        optimal_hours = []
        optimal_days = []
        
        for time_key, metrics in time_performance.items():
            if metrics["content_count"] > 0:
                avg_engagement = metrics["total_engagement"] / metrics["content_count"]
                
                if time_key.startswith("hour_"):
                    hour = int(time_key.split("_")[1])
                    optimal_hours.append({"hour": hour, "avg_engagement": avg_engagement})
                elif time_key.startswith("day_"):
                    day = time_key.split("_")[1]
                    optimal_days.append({"day": day, "avg_engagement": avg_engagement})
        
        # Sort by performance
        optimal_hours.sort(key=lambda x: x["avg_engagement"], reverse=True)
        optimal_days.sort(key=lambda x: x["avg_engagement"], reverse=True)
        
        return {
            "best_hours": optimal_hours[:5],
            "best_days": optimal_days[:3],
            "recommended_schedule": self._create_recommended_schedule(optimal_hours, optimal_days),
            "timing_insights": self._generate_timing_insights(optimal_hours, optimal_days)
        }
    
    async def _analyze_format_performance(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze performance by content format"""
        format_metrics = defaultdict(lambda: {
            "total_views": 0,
            "total_engagement": 0,
            "content_count": 0,
            "avg_engagement_rate": 0
        })
        
        for content in data.get("recent_content", []):
            content_type = content.get("content_type", "unknown")
            metrics = format_metrics[content_type]
            metrics["content_count"] += 1
            
            if "performance_metrics" in content:
                perf = content["performance_metrics"]
                metrics["total_views"] += perf.get("views", 0)
                metrics["total_engagement"] += perf.get("engagement", 0)
        
        # Calculate averages
        for format_type, metrics in format_metrics.items():
            if metrics["content_count"] > 0 and metrics["total_views"] > 0:
                metrics["avg_engagement_rate"] = metrics["total_engagement"] / metrics["total_views"]
                metrics["avg_views"] = metrics["total_views"] / metrics["content_count"]
        
        # Sort by performance
        sorted_formats = sorted(
            format_metrics.items(),
            key=lambda x: x[1]["avg_engagement_rate"],
            reverse=True
        )
        
        return {
            "format_rankings": dict(sorted_formats),
            "recommended_mix": self._calculate_optimal_content_mix(sorted_formats),
            "format_insights": self._generate_format_insights(sorted_formats)
        }
    
    async def _analyze_platform_performance(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze performance across different platforms"""
        platform_metrics = defaultdict(lambda: {
            "total_posts": 0,
            "total_engagement": 0,
            "avg_engagement_rate": 0,
            "top_content": []
        })
        
        # This would integrate with actual platform data
        # For now, we'll use mock data structure
        platforms = ["twitter", "linkedin", "email", "blog"]
        
        for platform in platforms:
            # Mock platform performance data
            platform_metrics[platform] = {
                "total_posts": 10 + hash(platform) % 20,
                "total_engagement": 500 + hash(platform) % 1000,
                "avg_engagement_rate": 0.03 + (hash(platform) % 100) / 1000,
                "growth_rate": -0.05 + (hash(platform) % 100) / 500,
                "top_content": []
            }
        
        return {
            "platform_rankings": dict(sorted(
                platform_metrics.items(),
                key=lambda x: x[1]["avg_engagement_rate"],
                reverse=True
            )),
            "cross_platform_insights": self._generate_platform_insights(platform_metrics),
            "platform_recommendations": self._recommend_platform_focus(platform_metrics)
        }
    
    async def _analyze_conversion_rates(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze conversion rates and CTA performance"""
        conversion_data = {
            "overall_conversion_rate": 0.025,  # 2.5% mock rate
            "cta_performance": {
                "Get Templates": {"clicks": 150, "conversions": 8, "rate": 0.053},
                "Learn More": {"clicks": 200, "conversions": 5, "rate": 0.025},
                "Start Free Trial": {"clicks": 80, "conversions": 6, "rate": 0.075},
                "Download Guide": {"clicks": 120, "conversions": 15, "rate": 0.125}
            },
            "content_type_conversion": {
                "blog": 0.02,
                "social": 0.015,
                "email": 0.045,
                "visual": 0.035
            }
        }
        
        return {
            "conversion_summary": conversion_data,
            "top_converting_ctas": self._rank_ctas_by_performance(conversion_data["cta_performance"]),
            "conversion_insights": self._generate_conversion_insights(conversion_data),
            "cta_recommendations": self._recommend_cta_improvements(conversion_data)
        }
    
    def _calculate_content_health_score(self, data: Dict[str, Any]) -> int:
        """Calculate overall content strategy health score (0-100)"""
        # Mock calculation based on various factors
        factors = {
            "content_volume": min(100, len(data.get("recent_content", [])) * 5),  # 20 posts = 100
            "engagement_quality": 75,  # Mock engagement quality
            "topic_diversity": 80,     # Mock topic diversity
            "platform_coverage": 85,  # Mock platform coverage
            "conversion_performance": 70  # Mock conversion performance
        }
        
        # Weighted average
        weights = {"content_volume": 0.2, "engagement_quality": 0.3, "topic_diversity": 0.2, "platform_coverage": 0.15, "conversion_performance": 0.15}
        
        health_score = sum(factors[factor] * weights[factor] for factor in factors)
        return int(health_score)
    
    # Mock data generators for when database is not available
    
    def _generate_mock_analysis(self) -> Dict[str, Any]:
        """Generate mock performance analysis"""
        return {
            "content_health_score": 78,
            "topic_performance": {
                "topic_rankings": {
                    "SaaS Design": {"avg_engagement_rate": 0.045, "content_count": 8},
                    "Framer Templates": {"avg_engagement_rate": 0.038, "content_count": 12},
                    "Conversion Optimization": {"avg_engagement_rate": 0.032, "content_count": 6}
                }
            },
            "optimal_timing": {
                "best_hours": [{"hour": 14, "avg_engagement": 0.042}, {"hour": 10, "avg_engagement": 0.038}],
                "best_days": [{"day": "Tuesday", "avg_engagement": 0.041}, {"day": "Wednesday", "avg_engagement": 0.039}]
            },
            "key_insights": [
                "SaaS design content performs 18% better than average",
                "Tuesday afternoons show highest engagement",
                "Visual content drives 25% more shares"
            ]
        }
    
    def _generate_mock_strategy_optimization(self) -> Dict[str, Any]:
        """Generate mock strategy optimization"""
        return {
            "strategy_optimization": {
                "focus_topics": ["SaaS Design", "Framer Templates", "Growth Hacking"],
                "optimal_schedule": {"Tuesday": "14:00", "Wednesday": "10:00", "Friday": "15:00"},
                "content_mix": {"blog": 0.4, "social": 0.3, "email": 0.2, "visual": 0.1},
                "prompt_improvements": ["Add more emotional triggers", "Include specific metrics", "Use urgency language"]
            },
            "expected_improvements": {
                "engagement_increase": "15-20%",
                "reach_improvement": "25-30%",
                "conversion_boost": "10-15%"
            }
        }
    
    def _generate_mock_competitor_tracking(self) -> Dict[str, Any]:
        """Generate mock competitor tracking"""
        return {
            "content_gaps": [
                {"topic": "AI in SaaS Design", "opportunity_score": 85},
                {"topic": "Mobile-First Templates", "opportunity_score": 78},
                {"topic": "Dark Mode Design", "opportunity_score": 72}
            ],
            "trending_topics": ["AI Tools", "No-Code Solutions", "Design Systems"],
            "competitive_opportunities": [
                "Create more tutorial content",
                "Focus on mobile design",
                "Develop AI-related templates"
            ]
        }
    
    def _generate_mock_report(self, report_type: str) -> Dict[str, Any]:
        """Generate mock report data"""
        return {
            "executive_summary": f"{report_type.title()} performance shows strong engagement with 15% growth",
            "content_summary": {"published": 8, "avg_engagement": 0.035, "top_performer": "SaaS Design Guide"},
            "recommendations": ["Increase visual content", "Post more on Tuesdays", "Focus on SaaS topics"]
        }
    
    # Additional helper methods would be implemented here for:
    # - Content analysis and categorization
    # - Virality prediction components
    # - Report formatting
    # - Recommendation generation
    # - Data visualization helpers
    
    def _extract_topics_from_content(self, content: Dict[str, Any]) -> List[str]:
        """Extract topics from content using keyword analysis"""
        title = content.get("title", "").lower()
        body = content.get("body", "").lower()
        
        topics = []
        
        # Check against content categories
        for category, keywords in self.content_categories.items():
            if any(keyword in title or keyword in body for keyword in keywords):
                topics.append(category)
        
        # Extract specific SaaS topics
        saas_topics = ["framer", "design", "template", "conversion", "optimization", "saas", "growth"]
        for topic in saas_topics:
            if topic in title or topic in body:
                topics.append(topic)
        
        return list(set(topics)) if topics else ["general"]
    
    def _analyze_emotional_triggers(self, title: str, body: str) -> Tuple[float, List[str]]:
        """Analyze emotional triggers in content"""
        text = (title + " " + body).lower()
        trigger_count = 0
        explanations = []
        
        for trigger in self.viral_indicators["emotional_triggers"]:
            if trigger in text:
                trigger_count += 1
                explanations.append(f"Contains emotional trigger: '{trigger}'")
        
        score = min(100, trigger_count * 15)  # 15 points per trigger, max 100
        return score, explanations
    
    def _analyze_urgency_factors(self, title: str, body: str) -> Tuple[float, List[str]]:
        """Analyze urgency factors in content"""
        text = (title + " " + body).lower()
        urgency_count = 0
        explanations = []
        
        for urgency_word in self.viral_indicators["urgency_words"]:
            if urgency_word in text:
                urgency_count += 1
                explanations.append(f"Contains urgency indicator: '{urgency_word}'")
        
        score = min(100, urgency_count * 20)  # 20 points per urgency word, max 100
        return score, explanations
    
    def _analyze_social_proof(self, title: str, body: str) -> Tuple[float, List[str]]:
        """Analyze social proof elements in content"""
        text = (title + " " + body).lower()
        social_count = 0
        explanations = []
        
        for social_word in self.viral_indicators["social_proof"]:
            if social_word in text:
                social_count += 1
                explanations.append(f"Contains social proof: '{social_word}'")
        
        score = min(100, social_count * 18)  # 18 points per social proof element, max 100
        return score, explanations
    
    def _analyze_trend_alignment(self, title: str, body: str, metadata: Dict[str, Any]) -> Tuple[float, List[str]]:
        """Analyze alignment with current trends"""
        trending_keywords = ["ai", "automation", "no-code", "remote", "productivity", "saas", "design system"]
        text = (title + " " + body).lower()
        
        trend_matches = sum(1 for keyword in trending_keywords if keyword in text)
        explanations = []
        
        if trend_matches > 0:
            explanations.append(f"Aligns with {trend_matches} trending topics")
        
        score = min(100, trend_matches * 25)  # 25 points per trend match, max 100
        return score, explanations
    
    def _analyze_shareability(self, title: str, body: str, content_type: str) -> Tuple[float, List[str]]:
        """Analyze shareability factors"""
        explanations = []
        score = 50  # Base shareability score
        
        # Title length optimization
        title_length = len(title)
        if 40 <= title_length <= 70:
            score += 15
            explanations.append("Title length optimized for sharing")
        
        # Content type bonus
        shareability_bonus = {
            "social": 20,
            "visual": 15,
            "blog": 10,
            "email": 5
        }
        
        score += shareability_bonus.get(content_type, 0)
        explanations.append(f"{content_type} format has good shareability")
        
        # Question in title
        if "?" in title:
            score += 10
            explanations.append("Question format increases engagement")
        
        return min(100, score), explanations
    
    def _analyze_saas_relevance(self, title: str, body: str) -> Tuple[float, List[str]]:
        """Analyze SaaS industry relevance"""
        saas_keywords = ["saas", "software", "app", "platform", "tool", "solution", "business", "startup", "growth", "revenue"]
        text = (title + " " + body).lower()
        
        relevance_count = sum(1 for keyword in saas_keywords if keyword in text)
        explanations = []
        
        if relevance_count > 0:
            explanations.append(f"High SaaS relevance with {relevance_count} industry keywords")
        
        score = min(100, relevance_count * 15 + 30)  # Base 30 + 15 per keyword
        return score, explanations
    
    def _analyze_format_bonus(self, content_type: str, metadata: Dict[str, Any]) -> Tuple[float, List[str]]:
        """Analyze format-specific bonuses"""
        format_scores = {
            "visual": 20,
            "social": 15,
            "blog": 10,
            "email": 8
        }
        
        score = format_scores.get(content_type, 5)
        explanations = [f"{content_type} format bonus applied"]
        
        return score, explanations
    
    def _suggest_virality_improvements(self, scores: Dict[str, float], content: Dict[str, Any]) -> List[str]:
        """Suggest improvements to increase virality potential"""
        improvements = []
        
        if scores["emotional_trigger"] < 30:
            improvements.append("Add more emotional triggers (amazing, shocking, secret, hack)")
        
        if scores["urgency_factor"] < 25:
            improvements.append("Include urgency words (now, today, limited, exclusive)")
        
        if scores["social_proof"] < 30:
            improvements.append("Add social proof elements (thousands use, experts recommend)")
        
        if scores["shareability"] < 60:
            improvements.append("Optimize title length (40-70 characters) and add questions")
        
        if scores["trend_alignment"] < 40:
            improvements.append("Align with trending topics (AI, automation, no-code)")
        
        return improvements
    
    def _estimate_reach(self, virality_score: float, content_type: str) -> Dict[str, int]:
        """Estimate potential reach based on virality score"""
        base_reach = {
            "blog": 500,
            "social": 1000,
            "email": 300,
            "visual": 800
        }
        
        base = base_reach.get(content_type, 500)
        multiplier = 1 + (virality_score / 100) * 10  # Up to 10x multiplier for perfect score
        
        return {
            "estimated_views": int(base * multiplier),
            "estimated_shares": int(base * multiplier * 0.1),
            "estimated_engagement": int(base * multiplier * 0.05)
        }
    
    def _calculate_success_probability(self, virality_score: float) -> str:
        """Calculate success probability based on virality score"""
        if virality_score >= 80:
            return "High (75-90%)"
        elif virality_score >= 60:
            return "Moderate (45-65%)"
        elif virality_score >= 40:
            return "Low (20-40%)"
        else:
            return "Minimal (5-20%)"
    
    # Additional helper methods for strategy optimization
    
    def _identify_winning_topics(self, topic_performance: Dict[str, Any]) -> List[str]:
        """Identify top performing topics for content focus"""
        topic_rankings = topic_performance.get("topic_rankings", {})
        
        # Sort topics by engagement rate
        sorted_topics = sorted(
            topic_rankings.items(),
            key=lambda x: x[1].get("avg_engagement_rate", 0),
            reverse=True
        )
        
        # Return top 5 topics
        return [topic for topic, _ in sorted_topics[:5]]
    
    def _optimize_publishing_schedule(self, timing_analysis: Dict[str, Any]) -> Dict[str, str]:
        """Create optimized publishing schedule"""
        best_hours = timing_analysis.get("best_hours", [])
        best_days = timing_analysis.get("best_days", [])
        
        schedule = {}
        
        # Map best days to best hours
        for i, day_info in enumerate(best_days[:3]):
            day = day_info.get("day", f"Day{i+1}")
            hour = best_hours[i % len(best_hours)].get("hour", 14) if best_hours else 14
            schedule[day] = f"{hour:02d}:00"
        
        return schedule
    
    def _optimize_content_mix(self, format_performance: Dict[str, Any]) -> Dict[str, float]:
        """Calculate optimal content format mix"""
        format_rankings = format_performance.get("format_rankings", {})
        
        if not format_rankings:
            # Default mix if no data
            return {"blog": 0.4, "social": 0.3, "email": 0.2, "visual": 0.1}
        
        # Calculate mix based on performance
        total_performance = sum(
            data.get("avg_engagement_rate", 0) for data in format_rankings.values()
        )
        
        if total_performance == 0:
            return {"blog": 0.4, "social": 0.3, "email": 0.2, "visual": 0.1}
        
        content_mix = {}
        for format_type, data in format_rankings.items():
            engagement_rate = data.get("avg_engagement_rate", 0)
            content_mix[format_type] = round(engagement_rate / total_performance, 2)
        
        return content_mix
    
    def _suggest_prompt_improvements(self, performance_analysis: Dict[str, Any]) -> List[str]:
        """Suggest improvements for AI prompts based on performance"""
        improvements = []
        
        # Analyze top performing content for patterns
        topic_performance = performance_analysis.get("topic_performance", {})
        winning_topics = topic_performance.get("topic_rankings", {})
        
        if winning_topics:
            top_topic = list(winning_topics.keys())[0] if winning_topics else "SaaS"
            improvements.append(f"Focus prompts on '{top_topic}' - it's your top performing topic")
        
        # General improvements based on virality factors
        improvements.extend([
            "Add more emotional triggers (amazing, shocking, secret)",
            "Include specific metrics and numbers in prompts",
            "Use urgency language (now, today, limited time)",
            "Add social proof elements (thousands use, experts recommend)",
            "Focus on actionable, step-by-step content"
        ])
        
        return improvements[:5]  # Return top 5 suggestions
    
    def _calculate_expected_improvements(self, focus_topics: List[str], optimal_schedule: Dict[str, str], content_mix: Dict[str, float]) -> Dict[str, str]:
        """Calculate expected improvements from optimization"""
        # Mock calculations based on optimization factors
        topic_boost = len(focus_topics) * 3  # 3% per focused topic
        schedule_boost = len(optimal_schedule) * 2  # 2% per optimized time slot
        mix_boost = len(content_mix) * 1  # 1% per format in mix
        
        total_boost = min(30, topic_boost + schedule_boost + mix_boost)  # Cap at 30%
        
        return {
            "engagement_increase": f"{total_boost-5}-{total_boost}%",
            "reach_improvement": f"{total_boost+5}-{total_boost+10}%",
            "conversion_boost": f"{max(5, total_boost//2)}-{total_boost//2+5}%"
        }
    
    def _prioritize_optimizations(self, focus_topics: List[str], optimal_schedule: Dict[str, str], content_mix: Dict[str, float], prompt_improvements: List[str]) -> List[Dict[str, Any]]:
        """Prioritize optimization actions by expected impact"""
        priorities = []
        
        if focus_topics:
            priorities.append({
                "action": "Focus on top performing topics",
                "priority": "High",
                "impact": "15-20% engagement increase",
                "effort": "Low",
                "topics": focus_topics[:3]
            })
        
        if optimal_schedule:
            priorities.append({
                "action": "Optimize publishing schedule",
                "priority": "Medium",
                "impact": "10-15% reach improvement",
                "effort": "Low",
                "schedule": optimal_schedule
            })
        
        if content_mix:
            priorities.append({
                "action": "Adjust content format mix",
                "priority": "Medium",
                "impact": "8-12% engagement improvement",
                "effort": "Medium",
                "mix": content_mix
            })
        
        if prompt_improvements:
            priorities.append({
                "action": "Improve AI prompts",
                "priority": "Low",
                "impact": "5-8% quality improvement",
                "effort": "High",
                "improvements": prompt_improvements[:3]
            })
        
        return priorities
    
    def _generate_next_actions(self, focus_topics: List[str], optimal_schedule: Dict[str, str], content_mix: Dict[str, float]) -> List[str]:
        """Generate specific next actions"""
        actions = []
        
        if focus_topics:
            actions.append(f"Create 3 pieces of content about '{focus_topics[0]}' this week")
        
        if optimal_schedule:
            next_day = list(optimal_schedule.keys())[0] if optimal_schedule else "Tuesday"
            next_time = list(optimal_schedule.values())[0] if optimal_schedule else "14:00"
            actions.append(f"Schedule next post for {next_day} at {next_time}")
        
        if content_mix:
            top_format = max(content_mix.items(), key=lambda x: x[1])[0]
            actions.append(f"Increase {top_format} content production by 20%")
        
        actions.extend([
            "Review and update AI prompts with winning topic keywords",
            "Set up automated posting schedule for optimal times",
            "Track performance metrics for next 7 days"
        ])
        
        return actions[:5]
    
    async def _generate_insights(self, topic_analysis: Dict[str, Any], timing_analysis: Dict[str, Any], format_analysis: Dict[str, Any], platform_analysis: Dict[str, Any], conversion_analysis: Dict[str, Any]) -> List[str]:
        """Generate key insights from analysis data"""
        insights = []
        
        # Topic insights
        topic_rankings = topic_analysis.get("topic_rankings", {})
        if topic_rankings:
            top_topic = list(topic_rankings.keys())[0]
            top_performance = list(topic_rankings.values())[0].get("avg_engagement_rate", 0)
            insights.append(f"'{top_topic}' content performs {int(top_performance * 100)}% better than average")
        
        # Timing insights
        best_hours = timing_analysis.get("best_hours", [])
        if best_hours:
            best_hour = best_hours[0].get("hour", 14)
            insights.append(f"Content posted at {best_hour}:00 gets highest engagement")
        
        # Format insights
        format_rankings = format_analysis.get("format_rankings", {})
        if format_rankings:
            top_format = list(format_rankings.keys())[0]
            insights.append(f"{top_format.title()} content drives 25% more engagement")
        
        # Platform insights
        platform_rankings = platform_analysis.get("platform_rankings", {})
        if platform_rankings:
            top_platform = list(platform_rankings.keys())[0]
            insights.append(f"{top_platform.title()} is your highest performing platform")
        
        # Conversion insights
        conversion_summary = conversion_analysis.get("conversion_summary", {})
        overall_rate = conversion_summary.get("overall_conversion_rate", 0)
        insights.append(f"Overall conversion rate is {overall_rate * 100:.1f}%")
        
        return insights
    
    async def _generate_recommendations(self, insights: List[str]) -> List[Dict[str, Any]]:
        """Generate actionable recommendations from insights"""
        recommendations = []
        
        recommendations.append({
            "category": "Content Strategy",
            "priority": "High",
            "action": "Focus on top-performing topics",
            "rationale": "Data shows certain topics drive significantly higher engagement",
            "expected_impact": "15-20% engagement increase"
        })
        
        recommendations.append({
            "category": "Publishing Schedule",
            "priority": "Medium",
            "action": "Optimize posting times",
            "rationale": "Timing analysis reveals clear patterns in audience engagement",
            "expected_impact": "10-15% reach improvement"
        })
        
        recommendations.append({
            "category": "Content Mix",
            "priority": "Medium",
            "action": "Adjust format distribution",
            "rationale": "Some content formats consistently outperform others",
            "expected_impact": "8-12% overall performance boost"
        })
        
        recommendations.append({
            "category": "Platform Focus",
            "priority": "Low",
            "action": "Prioritize high-performing platforms",
            "rationale": "Resource allocation should match platform performance",
            "expected_impact": "5-10% efficiency improvement"
        })
        
        return recommendations
    
    # Mock competitor analysis methods
    
    async def _analyze_competitor(self, competitor: Dict[str, str]) -> Dict[str, Any]:
        """Analyze individual competitor (mock implementation)"""
        return {
            "posting_frequency": 3.5,  # posts per week
            "avg_engagement": 0.035,
            "top_topics": ["design", "templates", "saas"],
            "content_types": {"blog": 0.4, "social": 0.6},
            "recent_launches": [],
            "content_gaps": ["mobile design", "ai tools"]
        }
    
    def _identify_content_gaps(self, analysis: Dict[str, Any], focus: str) -> List[Dict[str, Any]]:
        """Identify content gaps from competitor analysis"""
        return [
            {"topic": f"{focus} automation", "opportunity_score": 85},
            {"topic": f"advanced {focus}", "opportunity_score": 78}
        ]
    
    def _extract_trending_topics(self, analysis: Dict[str, Any]) -> List[str]:
        """Extract trending topics from competitor analysis"""
        return analysis.get("top_topics", [])
    
    def _consolidate_content_gaps(self, gaps: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Consolidate content gaps from all competitors"""
        # Mock consolidation
        return sorted(gaps, key=lambda x: x.get("opportunity_score", 0), reverse=True)[:10]
    
    def _summarize_trending_topics(self, topics: List[str]) -> List[str]:
        """Summarize trending topics across competitors"""
        topic_counts = Counter(topics)
        return [topic for topic, count in topic_counts.most_common(10)]
    
    def _identify_competitive_opportunities(self, competitor_analysis: Dict[str, Any]) -> List[str]:
        """Identify competitive opportunities"""
        return [
            "Create more tutorial content",
            "Focus on mobile-first design",
            "Develop AI-powered templates",
            "Increase posting frequency",
            "Expand into video content"
        ]
    
    def _generate_market_insights(self, competitor_analysis: Dict[str, Any]) -> List[str]:
        """Generate market insights from competitor data"""
        return [
            "Market is shifting towards AI-powered design tools",
            "Mobile-first approach is becoming standard",
            "Video content is gaining traction in SaaS space",
            "Community-driven content performs best"
        ]
    
    def _suggest_competitive_responses(self, opportunities: List[str]) -> List[Dict[str, str]]:
        """Suggest responses to competitive opportunities"""
        return [
            {"opportunity": opportunities[0] if opportunities else "General improvement", "response": "Launch tutorial series", "timeline": "2 weeks"},
            {"opportunity": opportunities[1] if len(opportunities) > 1 else "Content expansion", "response": "Create mobile templates", "timeline": "1 month"}
        ]
    
    # Additional missing methods for report generation
    
    async def _get_period_performance(self, days: int, offset: int = 0) -> Dict[str, Any]:
        """Get performance data for a specific period"""
        # Mock performance data
        return {
            "total_content": 10 + (days // 7) * 3,
            "total_views": 5000 + days * 200,
            "total_engagement": 250 + days * 15,
            "avg_engagement_rate": 0.035 + (days % 3) * 0.005,
            "top_performing": [
                {"title": "SaaS Design Guide", "views": 1200, "engagement": 84},
                {"title": "Framer Templates", "views": 980, "engagement": 67}
            ]
        }
    
    def _calculate_performance_trends(self, current: Dict[str, Any], comparison: Dict[str, Any]) -> Dict[str, Any]:
        """Calculate performance trends between periods"""
        current_engagement = current.get("avg_engagement_rate", 0.035)
        comparison_engagement = comparison.get("avg_engagement_rate", 0.030)
        
        engagement_change = ((current_engagement - comparison_engagement) / comparison_engagement) * 100 if comparison_engagement > 0 else 0
        
        return {
            "engagement_rate_change": round(engagement_change, 1),
            "views_change": 15.3,  # Mock data
            "content_volume_change": 8.7,  # Mock data
            "trend_direction": "up" if engagement_change > 0 else "down"
        }
    
    async def _get_top_performing_content(self, days: int) -> List[Dict[str, Any]]:
        """Get top performing content for period"""
        return [
            {
                "title": "The Ultimate SaaS Design Guide",
                "content_type": "blog",
                "views": 1200,
                "engagement": 84,
                "engagement_rate": 0.07,
                "published_date": "2024-01-01"
            },
            {
                "title": "10 Framer Templates That Convert",
                "content_type": "social",
                "views": 980,
                "engagement": 67,
                "engagement_rate": 0.068,
                "published_date": "2024-01-02"
            }
        ]
    
    def _generate_executive_summary(self, current_performance: Dict[str, Any], trends: Dict[str, Any], top_content: List[Dict[str, Any]], report_type: str) -> str:
        """Generate executive summary for reports"""
        engagement_change = trends.get("engagement_rate_change", 0)
        trend_direction = "increased" if engagement_change > 0 else "decreased"
        
        return f"{report_type.title()} performance shows engagement has {trend_direction} by {abs(engagement_change):.1f}%. " \
               f"Published {current_performance.get('total_content', 0)} pieces of content with " \
               f"{current_performance.get('total_views', 0)} total views. " \
               f"Top performer: '{top_content[0]['title'] if top_content else 'N/A'}' with {top_content[0]['views'] if top_content else 0} views."
    
    def _create_content_summary(self, performance: Dict[str, Any], days: int) -> Dict[str, Any]:
        """Create content summary section"""
        return {
            "content_published": performance.get("total_content", 0),
            "total_views": performance.get("total_views", 0),
            "total_engagement": performance.get("total_engagement", 0),
            "avg_engagement_rate": performance.get("avg_engagement_rate", 0),
            "content_per_day": performance.get("total_content", 0) / days if days > 0 else 0,
            "views_per_content": performance.get("total_views", 0) / max(performance.get("total_content", 1), 1)
        }
    
    def _create_engagement_analysis(self, performance: Dict[str, Any], trends: Dict[str, Any]) -> Dict[str, Any]:
        """Create engagement analysis section"""
        return {
            "current_rate": performance.get("avg_engagement_rate", 0),
            "rate_change": trends.get("engagement_rate_change", 0),
            "trend_direction": trends.get("trend_direction", "stable"),
            "engagement_quality": "high" if performance.get("avg_engagement_rate", 0) > 0.04 else "moderate",
            "improvement_areas": ["Increase visual content", "Optimize posting times", "Focus on trending topics"]
        }
    
    def _create_platform_breakdown(self, performance: Dict[str, Any]) -> Dict[str, Any]:
        """Create platform performance breakdown"""
        return {
            "twitter": {"posts": 5, "engagement_rate": 0.038, "growth": "+12%"},
            "linkedin": {"posts": 3, "engagement_rate": 0.045, "growth": "+8%"},
            "email": {"campaigns": 2, "open_rate": 0.28, "growth": "+15%"},
            "blog": {"posts": 2, "avg_time_on_page": "3:45", "growth": "+22%"}
        }
    
    async def _create_report_recommendations(self, performance: Dict[str, Any], trends: Dict[str, Any]) -> List[Dict[str, str]]:
        """Create recommendations for reports"""
        recommendations = []
        
        engagement_rate = performance.get("avg_engagement_rate", 0)
        engagement_change = trends.get("engagement_rate_change", 0)
        
        if engagement_rate < 0.03:
            recommendations.append({
                "category": "Engagement",
                "recommendation": "Focus on more interactive content formats",
                "priority": "High",
                "expected_impact": "15-25% engagement increase"
            })
        
        if engagement_change < 0:
            recommendations.append({
                "category": "Content Strategy",
                "recommendation": "Analyze top performers and replicate successful patterns",
                "priority": "Medium",
                "expected_impact": "10-15% performance recovery"
            })
        
        recommendations.append({
            "category": "Optimization",
            "recommendation": "Test posting times and content formats",
            "priority": "Medium",
            "expected_impact": "5-10% reach improvement"
        })
        
        return recommendations
    
    def _generate_next_steps(self, recommendations: List[Dict[str, str]]) -> List[str]:
        """Generate next steps from recommendations"""
        next_steps = []
        
        for rec in recommendations[:3]:  # Top 3 recommendations
            if rec.get("category") == "Engagement":
                next_steps.append("Create 2 interactive posts this week")
            elif rec.get("category") == "Content Strategy":
                next_steps.append("Analyze top 3 performing posts for patterns")
            elif rec.get("category") == "Optimization":
                next_steps.append("A/B test posting times for next 5 posts")
        
        next_steps.extend([
            "Review analytics daily for trend changes",
            "Update content calendar based on insights"
        ])
        
        return next_steps[:5]
    
    def _format_html_report(self, report_data: Dict[str, Any]) -> str:
        """Format report as HTML email"""
        metadata = report_data.get("report_metadata", {})
        summary = report_data.get("executive_summary", "")
        recommendations = report_data.get("recommendations", [])
        
        html = f"""
        <html>
        <head><title>CRAEFTO {metadata.get('type', 'Daily').title()} Report</title></head>
        <body style="font-family: Arial, sans-serif; margin: 20px;">
            <h1>üöÄ CRAEFTO {metadata.get('type', 'Daily').title()} Report</h1>
            <p><strong>Period:</strong> {metadata.get('period', 'N/A')}</p>
            <p><strong>Generated:</strong> {metadata.get('generated_at', 'N/A')}</p>
            
            <h2>üìä Executive Summary</h2>
            <p>{summary}</p>
            
            <h2>üí° Key Recommendations</h2>
            <ul>
        """
        
        for rec in recommendations[:3]:
            html += f"<li><strong>{rec.get('category', 'General')}:</strong> {rec.get('recommendation', 'N/A')}</li>"
        
        html += """
            </ul>
            
            <h2>üéØ Next Steps</h2>
            <ul>
        """
        
        for step in report_data.get("next_steps", [])[:3]:
            html += f"<li>{step}</li>"
        
        html += """
            </ul>
            
            <p><em>Generated by CRAEFTO Business Intelligence</em></p>
        </body>
        </html>
        """
        
        return html
    
    def _format_slack_message(self, report_data: Dict[str, Any]) -> str:
        """Format report as Slack message"""
        metadata = report_data.get("report_metadata", {})
        summary = report_data.get("executive_summary", "")
        recommendations = report_data.get("recommendations", [])
        
        message = f"""
üöÄ *CRAEFTO {metadata.get('type', 'Daily').title()} Report*

üìä *Executive Summary*
{summary}

üí° *Top Recommendations*
"""
        
        for i, rec in enumerate(recommendations[:3], 1):
            message += f"{i}. *{rec.get('category', 'General')}:* {rec.get('recommendation', 'N/A')}\n"
        
        message += "\nüéØ *Next Steps*\n"
        
        for i, step in enumerate(report_data.get("next_steps", [])[:3], 1):
            message += f"{i}. {step}\n"
        
        message += f"\n_Generated at {metadata.get('generated_at', 'N/A')}_"
        
        return message


# Utility functions for standalone usage
async def analyze_content_performance(days: int = 7) -> Dict[str, Any]:
    """Standalone function to analyze content performance"""
    intelligence = BusinessIntelligence()
    intelligence.metrics_window = days
    return await intelligence.analyze_performance()

async def optimize_strategy() -> Dict[str, Any]:
    """Standalone function to optimize content strategy"""
    intelligence = BusinessIntelligence()
    return await intelligence.optimize_content_strategy()

async def track_competitors() -> Dict[str, Any]:
    """Standalone function to track competitor content"""
    intelligence = BusinessIntelligence()
    return await intelligence.competitor_tracking()

async def generate_daily_report() -> Dict[str, Any]:
    """Standalone function to generate daily report"""
    intelligence = BusinessIntelligence()
    return await intelligence.generate_report("daily")

def predict_content_virality(content: Dict[str, Any]) -> Dict[str, Any]:
    """Standalone function to predict content virality"""
    intelligence = BusinessIntelligence()
    return intelligence.predict_virality(content)
